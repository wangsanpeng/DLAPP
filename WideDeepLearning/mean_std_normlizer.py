#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Time    : 17/11/9 AM10:03
# @Author  : shaoguang.csg
# @File    : mean_std_normlizer.py

from multiprocessing import (Pool, cpu_count)
from multiprocessing.dummy import Pool as ThreadPool
from functools import partial
import os
import pickle

import pandas as pd

from normalizer import Normalizer
from utils.mean_std import cal_mean_var, apply_mean_var, reverse_mean_std
from utils.pandas_helper import (cal_square_sum, get_unique_values)
from utils.logger import logger

pd.set_option('display.multi_sparse', False)


class MeanStdNormalizer(Normalizer):

    def __init__(self, columns=None, groupby_key=None, big_data_mode=False, with_mean=True, with_std=True):
        super(MeanStdNormalizer, self).__init__(columns, groupby_key, big_data_mode)

        self.with_mean = with_mean
        self.with_std = with_std

        self._mean_var = None
        self._g_mean_var = None

    def fit(self, data):
        """

        :param data: DataFrame when big_data_mode is False, otherwise chunks generated by pandas.readcsv
        :return:
        """
        if self._big_data_mode:
            func = partial(_func, self._columns, self._groupby_key)
            pool = ThreadPool(4)
            result = pool.map(func, data)
            pool.close()
            pool.join()

            self._mean_var, self._g_mean_var = self._parse_result(result, self._columns)
        else:
            self._mean_var = cal_mean_var(data, columns=self._columns, groupby_key=self._groupby_key)
            self._g_mean_var = cal_mean_var(data, columns=self._columns)

    def transform(self, df, columns):
        if len(columns) == 0:
            logger.warning("size of columns is 0")
            return df

        for column in columns:
            if column not in self._columns:
                logger.error("{column} not found in normed columns {}".format(column, self._columns))
                raise Exception

        return apply_mean_var(
            df,
            self._mean_var,
            self._g_mean_var,
            columns=columns,
            groupby_key=self._groupby_key
        )

    def reverse_transform(self, df, columns=None, use_columns=None):
        if len(use_columns) == 0:
            logger.warning("size of columns is 0")
            return df

        for column in use_columns:
            if column not in self._columns:
                logger.error("{column} not found in normed columns {}".format(column, self._columns))
                raise Exception

        return reverse_mean_std(
            df,
            self._mean_var,
            self._g_mean_var,
            columns=columns,
            use_columns=use_columns,
            groupby_key=self._groupby_key
        )

    def save_to_file(self, path):
        self._mean_var.to_csv(os.path.join(path, '_mean_var'))
        self._g_mean_var.to_csv(os.path.join(path, '_g_mean_var'))

    def load_from_file(self, path):
        for filename in ['_mean_var', '_mean_var']:
            if not os.path.exists(os.path.join(path, filename)):
                logger.error("{} not exists".format(os.path.join(path, filename)))
                raise FileNotFoundError

        self._mean_var = pd.read_csv(os.path.join(path, '_mean_var'), index_col=0, skipinitialspace=True, header=[0,1])
        self._g_mean_var = pd.read_csv(os.path.join(path, '_g_mean_var'), index_col=0, skipinitialspace=True, header=[0,1])

    def get_mean_var(self):
        return self._mean_var

    def get_g_mean_var(self):
        return self._g_mean_var

    def _parse_result(self, result, columns):
        chunk_shape, chunk_size = result[0][2], result[0][5]
        mean_var, g_mean_var, square_sum, g_square_sum = \
            result[0][0].mul(chunk_shape, level=0), \
            result[0][1]*chunk_size, \
            result[0][3], \
            result[0][4]

        for idx in range(1, len(result)):
            current_chunk_shape, current_chunk_size = result[idx][2], result[idx][5]
            mean_var = mean_var.add(result[idx][0].mul(current_chunk_shape, level=0), fill_value=0.0)
            g_mean_var = g_mean_var.add(result[idx][1]*current_chunk_size, fill_value=0.0)

            square_sum = square_sum.add(result[idx][3], fill_value=0.0)
            g_square_sum = g_square_sum.add(result[idx][4], fill_value=0.0)

            chunk_shape = chunk_shape.add(current_chunk_shape, fill_value=0.0)
            chunk_size += current_chunk_size

        mean_var = mean_var.div(chunk_shape, level=0)
        g_mean_var /= chunk_size
        mean_var = _estimated_mean_var(mean_var, square_sum, chunk_shape, columns)
        g_mean_var = _estimated_mean_var(g_mean_var, g_square_sum, chunk_size, columns)
        return mean_var, g_mean_var


def _estimated_mean_var(mean_var, square_sum, size, columns=None):
    tmp = square_sum.div(size)
    for column in columns:
        mean_var[column, '_var'] = tmp[column].sub(mean_var[column]['mean']*mean_var[column]['mean'], fill_value=0.0)
    return mean_var


def _func(columns, groupby_key, chunk):
    if groupby_key is None:
        chunk_shape = chunk[columns].groupby(lambda _:1).count()
    else:
        chunk_shape = chunk[columns+[groupby_key]].groupby(groupby_key).count()

    return cal_mean_var(chunk, columns, groupby_key, only_mean=True),\
           cal_mean_var(chunk, columns, only_mean=True), \
           chunk_shape, \
           cal_square_sum(chunk, columns, groupby_key), \
           cal_square_sum(chunk, columns),\
           chunk.shape[0]

if __name__ == '__main__':
    filename = '/Users/cheng/Data/data/cate_gmv/train_set'
    df = pd.read_csv(filename, sep=',', header='infer', engine='c')

    norm1 = MeanStdNormalizer(big_data_mode=False)
    norm1.fit(df, columns=['f1', 'target'], groupby_key='leaf_cate_id')
    norm1.save_to_file('.')

    norm2 = MeanStdNormalizer(big_data_mode=False)
    norm2.load_from_file('.')

